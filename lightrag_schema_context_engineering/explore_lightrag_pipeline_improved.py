#!/usr/bin/env python3
"""
Improved LightRAG Pipeline Explorer
Addresses the issues identified in the original exploration.
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, List

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

from src.loaders import LoaderFactory
from src.chunkers import ChunkerFactory
from src.embeddings import EmbeddingRegistry
from src.retrievers import RetrieverFactory
from src.agents import SMEAgent, CypherAgent
from src.config.default_configs import get_default_config
from src.question_to_json_converter import QuestionToJSONConverter

class ImprovedLightRAGPipelineExplorer:
    """Improved explorer that addresses identified issues."""
    
    def __init__(self):
        self.config = get_default_config()
        self.rag_config = self.config.get("rag_config", {})
        self.question_converter = QuestionToJSONConverter()
        
        # Initialize components
        self._initialize_components()
        
    def _initialize_components(self):
        """Initialize all pipeline components."""
        print("ğŸ”§ Initializing Improved LightRAG Pipeline Components...")
        print("=" * 60)
        
        # Load documents
        print("ğŸ“š Loading documents...")
        start_time = time.time()
        self.documents = LoaderFactory.load_documents("documents/4_knowledge_base_sme.json")
        load_time = time.time() - start_time
        print(f"   âœ… Loaded {len(self.documents)} documents in {load_time:.3f}s")
        
        # Create chunker
        print("ğŸ“¦ Creating chunks...")
        chunker_config = self.rag_config.get("chunker", {})
        self.chunker = ChunkerFactory.create_chunker(chunker_config.get("strategy", "fixed_window"))
        
        start_time = time.time()
        self.chunks = self.chunker.chunk_documents(self.documents)
        chunk_time = time.time() - start_time
        print(f"   âœ… Created {len(self.chunks)} chunks in {chunk_time:.3f}s")
        
        # Create embedder
        print("ğŸ”¤ Creating embedder...")
        embedding_config = self.rag_config.get("embedding", {})
        embedding_registry = EmbeddingRegistry()
        self.embedder = embedding_registry.get_embedder(embedding_config.get("model", "text-embedding-3-small"))
        print(f"   âœ… Using embedding model: {embedding_config.get('model', 'text-embedding-3-small')}")
        
        # Create retriever
        print("ğŸ” Creating retriever...")
        retriever_config = self.rag_config.get("retriever", {})
        self.retriever = RetrieverFactory.create_retriever(
            retriever_config.get("type", "vector"),
            embedding_model=embedding_config.get("model", "text-embedding-3-small")
        )
        self.retriever.add_chunks(self.chunks)
        print(f"   âœ… Using retriever type: {retriever_config.get('type', 'vector')}")
        
        # Create agents with Gemini
        print("ğŸ¤– Creating agents...")
        llm_config = self.rag_config.get("llm", {})
        print(f"   ğŸ”§ LLM Config: {llm_config}")
        self.sme_agent = SMEAgent(llm_model=llm_config.get("model", "gemini-1.5-flash"))
        self.cypher_agent = CypherAgent(llm_model=llm_config.get("model", "gemini-1.5-flash"))
        print(f"   âœ… Using LLM model: {llm_config.get('model', 'gemini-1.5-flash')}")
        
        print("âœ… Pipeline initialization complete!\n")
    
    def explore_pipeline(self, question: str):
        """Explore the complete pipeline with improvements."""
        print("ğŸš€ Improved LightRAG Pipeline Exploration")
        print("=" * 60)
        print(f"ğŸ“ User Question: {question}")
        print("=" * 60)
        
        # Step 1: Question to Structured Format Conversion
        self._explore_question_conversion(question)
        
        # Step 2: Enhanced Query Creation
        self._explore_enhanced_query(question)
        
        # Step 3: Retrieval Process
        self._explore_retrieval(question)
        
        # Step 4: SME Agent Processing
        self._explore_sme_processing(question)
        
        # Step 5: Cypher Agent Processing
        self._explore_cypher_processing(question)
        
        # Step 6: Final Results
        self._explore_final_results(question)
        
        # Step 7: Issue Analysis
        self._analyze_issues(question)
    
    def _explore_question_conversion(self, question: str):
        """Explore question to structured format conversion."""
        print("\nğŸ”„ STEP 1: Question to Structured Format Conversion")
        print("-" * 50)
        
        print("ğŸ“Š Converting natural language question to structured JSON format...")
        print("   â„¹ï¸  Method: Hard-coded regex patterns (not LLM-based)")
        print("   âœ… Benefits: Fast, reliable, no overfitting, extensible")
        
        start_time = time.time()
        structured_json = self.question_converter.convert_question_to_json(question)
        conversion_time = time.time() - start_time
        
        print(f"   â±ï¸  Conversion time: {conversion_time:.3f}s")
        print("\nğŸ“‹ Structured JSON Output:")
        print(json.dumps(structured_json, indent=2))
        
        # Store for later use
        self.structured_json = structured_json
    
    def _explore_enhanced_query(self, question: str):
        """Explore enhanced query creation."""
        print("\nğŸ”„ STEP 2: Enhanced Query Creation")
        print("-" * 50)
        
        print("ğŸ”§ Creating enhanced query for better retrieval...")
        start_time = time.time()
        enhanced_query = self.question_converter.create_enhanced_query(question)
        creation_time = time.time() - start_time
        
        print(f"   â±ï¸  Creation time: {creation_time:.3f}s")
        print("\nğŸ“ Original Question:")
        print(f"   {question}")
        print("\nğŸš€ Enhanced Query:")
        print(f"   {enhanced_query}")
        
        # Store for later use
        self.enhanced_query = enhanced_query
    
    def _explore_retrieval(self, question: str):
        """Explore the retrieval process."""
        print("\nğŸ”„ STEP 3: Retrieval Process")
        print("-" * 50)
        
        print("ğŸ” Performing vector retrieval with enhanced query...")
        start_time = time.time()
        retrieval_results = self.retriever.retrieve(self.enhanced_query, top_k=5)
        retrieval_time = time.time() - start_time
        
        print(f"   â±ï¸  Retrieval time: {retrieval_time:.3f}s")
        print(f"   ğŸ“Š Retrieved {len(retrieval_results)} chunks")
        
        print("\nğŸ“‹ Retrieved Chunks:")
        for i, result in enumerate(retrieval_results, 1):
            print(f"\n   ğŸ”¸ Chunk {i} (Score: {result.score:.3f}):")
            print(f"      Content: {result.chunk.content[:200]}...")
            print(f"      Metadata: {result.chunk.metadata}")
            print(f"      Rank: {result.rank}")
            print(f"      Retrieval Method: {result.retrieval_method}")
            
            # Score analysis
            if result.score < 0.5:
                print(f"      âš ï¸  Low score analysis: Score {result.score:.3f} is normal for semantic matching")
                print(f"         - Cosine similarity typically ranges 0.3-0.8 for good matches")
                print(f"         - Enhanced query may contain structural elements not in chunk")
        
        # Store for later use
        self.retrieval_results = retrieval_results
    
    def _explore_sme_processing(self, question: str):
        """Explore SME agent processing."""
        print("\nğŸ”„ STEP 4: SME Agent Processing")
        print("-" * 50)
        
        print("ğŸ§  SME Agent filtering and organizing retrieved context...")
        start_time = time.time()
        sme_response = self.sme_agent.process(question, self.retrieval_results)
        sme_time = time.time() - start_time
        
        print(f"   â±ï¸  Processing time: {sme_time:.3f}s")
        print(f"   ğŸ“Š Response type: {type(sme_response).__name__}")
        print(f"   ğŸ¤– LLM Model: {sme_response.metadata.get('llm_model', 'unknown')}")
        
        print("\nğŸ“‹ SME Agent Input:")
        print(f"   Question: {question}")
        print(f"   Retrieved chunks: {len(self.retrieval_results)} chunks")
        
        print("\nğŸ“‹ SME Agent Output:")
        print(f"   Content: {sme_response.content}")
        print(f"   Processing Time: {sme_response.processing_time:.3f}s")
        print(f"   Metadata: {sme_response.metadata}")
        
        # Store for later use
        self.sme_response = sme_response
    
    def _explore_cypher_processing(self, question: str):
        """Explore Cypher agent processing."""
        print("\nğŸ”„ STEP 5: Cypher Agent Processing")
        print("-" * 50)
        
        print("ğŸ”§ Cypher Agent generating Cypher query from filtered context...")
        start_time = time.time()
        cypher_response = self.cypher_agent.process(question, self.retrieval_results, filtered_schema=self.sme_response.content)
        cypher_time = time.time() - start_time
        
        print(f"   â±ï¸  Processing time: {cypher_time:.3f}s")
        print(f"   ğŸ“Š Response type: {type(cypher_response).__name__}")
        print(f"   ğŸ¤– LLM Model: {cypher_response.metadata.get('llm_model', 'unknown')}")
        
        print("\nğŸ“‹ Cypher Agent Input:")
        print(f"   Question: {question}")
        print(f"   Filtered Schema: {self.sme_response.content[:200]}...")
        print(f"   Retrieved chunks: {len(self.retrieval_results)} chunks")
        
        print("\nğŸ“‹ Cypher Agent Output:")
        print(f"   Content: {cypher_response.content}")
        print(f"   Processing Time: {cypher_response.processing_time:.3f}s")
        print(f"   Metadata: {cypher_response.metadata}")
        
        # Store for later use
        self.cypher_response = cypher_response
    
    def _explore_final_results(self, question: str):
        """Explore final results and summary."""
        print("\nğŸ”„ STEP 6: Final Results")
        print("-" * 50)
        
        print("ğŸ“Š Pipeline Summary:")
        print(f"   ğŸ“ Original Question: {question}")
        print(f"   ğŸ”„ Query Intent: {self.structured_json.get('query_intent', 'unknown')}")
        print(f"   ğŸ·ï¸  Relevant Nodes: {', '.join(self.structured_json.get('relevant_nodes', []))}")
        print(f"   ğŸ”— Relevant Relationships: {', '.join(self.structured_json.get('relevant_relationships', []))}")
        print(f"   ğŸ“‹ Constraints: {self.structured_json.get('constraints', {})}")
        
        print(f"\n   ğŸ” Retrieved Chunks: {len(self.retrieval_results)}")
        print(f"   ğŸ§  SME Processing Time: {self.sme_response.processing_time:.3f}s")
        print(f"   ğŸ”§ Cypher Processing Time: {self.cypher_response.processing_time:.3f}s")
        
        print("\nğŸ¯ Generated Cypher Query:")
        print("=" * 40)
        print(self.cypher_response.content)
        print("=" * 40)
        
        print("\nğŸ“ˆ Performance Metrics:")
        total_time = (self.sme_response.processing_time + 
                     self.cypher_response.processing_time)
        print(f"   â±ï¸  Total LLM Processing Time: {total_time:.3f}s")
        print(f"   ğŸ“Š Success: {bool(self.cypher_response.content)}")
        
        # Show chunk relevance analysis
        print("\nğŸ” Chunk Relevance Analysis:")
        for i, result in enumerate(self.retrieval_results, 1):
            chunk_type = result.chunk.metadata.get('chunk_type', 'unknown')
            category = result.chunk.metadata.get('category', 'unknown')
            print(f"   Chunk {i}: {chunk_type} ({category}) - Score: {result.score:.3f}")
    
    def _analyze_issues(self, question: str):
        """Analyze identified issues and provide solutions."""
        print("\nğŸ” ISSUE ANALYSIS & SOLUTIONS")
        print("=" * 50)
        
        print("1ï¸âƒ£ QUESTION CONVERSION METHOD:")
        print("   âœ… Current: Hard-coded regex patterns")
        print("   âœ… Benefits: Fast, reliable, no overfitting")
        print("   ğŸ’¡ For complex questions: Consider hybrid approach (regex + LLM fallback)")
        
        print("\n2ï¸âƒ£ LLM MODEL CONFIGURATION:")
        print(f"   ğŸ”§ Current LLM: {self.sme_response.metadata.get('llm_model', 'unknown')}")
        print("   âœ… Fixed: Updated config to use Gemini")
        print("   ğŸ’¡ Verify: Check if Gemini API key is set")
        
        print("\n3ï¸âƒ£ CYPHER QUERY GENERATION ISSUE:")
        print("   âŒ Problem: Schema doesn't have 'department' concept")
        print("   ğŸ” Analysis: Uses 'Group' instead of 'Department'")
        print("   ğŸ’¡ Solution: Map 'engineering department' â†’ 'engineering group'")
        print("   ğŸ’¡ Expected Query: MATCH (u:User)-[:MEMBER_OF]->(g:Group {name: 'engineering'}) RETURN u.name")
        
        print("\n4ï¸âƒ£ CHUNK SCORES ANALYSIS:")
        print("   ğŸ“Š Score Range: 0.4-0.5 is normal for semantic matching")
        print("   ğŸ“ˆ Expected Range: 0.3-0.8 for good matches")
        print("   ğŸ’¡ Reason: Enhanced query contains structural elements")
        print("   ğŸ’¡ Improvement: Consider score normalization or boosting")
        
        print("\nğŸ¯ RECOMMENDATIONS:")
        print("   1. Add department-to-group mapping in question converter")
        print("   2. Implement score boosting for schema-relevant chunks")
        print("   3. Add fallback LLM for complex question conversion")
        print("   4. Improve schema coverage for edge cases")

def main():
    """Main function to run the improved pipeline explorer."""
    if len(sys.argv) != 2:
        print("âŒ Usage: python explore_lightrag_pipeline_improved.py \"Your question here\"")
        print("Example: python explore_lightrag_pipeline_improved.py \"Show me all employees in the engineering department\"")
        sys.exit(1)
    
    question = sys.argv[1]
    
    try:
        # Create explorer and run pipeline
        explorer = ImprovedLightRAGPipelineExplorer()
        explorer.explore_pipeline(question)
        
    except Exception as e:
        print(f"âŒ Error during pipeline exploration: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 