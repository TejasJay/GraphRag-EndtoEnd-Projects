{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1727db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is for finding relevant PROJECTS based on their description\n",
    "openai_project_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name=\"openai_project_index\",\n",
    "    node_label=\"Project\",\n",
    "    text_node_properties=[\"name\", \"description\", \"complexity\"],\n",
    "    embedding_node_property=\"openai_embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d998ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details_chat_template_str = \"\"\"\n",
    "Your job is to use the provided project data to answer \n",
    "questions about their status, description, startdate, enddate, etc. \n",
    "within the company. Use the following context to answer questions. \n",
    "Be as detailed as possible, but don't make up any information that's \n",
    "not from the context. If you don't know an answer, say you don't know.\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc1c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"project-qa-tool\", return_direct=False)\n",
    "def project_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering questions about projects.\"\"\"\n",
    "    \n",
    "    project_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"context\"],\n",
    "            template=project_details_chat_template_str))\n",
    "    \n",
    "    human_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=\"Can you provide details on: {question}?\"))\n",
    "    \n",
    "    messages = [project_details_chat_template_str, human_prompt]\n",
    "    \n",
    "    qa_prompt = ChatPromptTemplate(\n",
    "        messages=messages,\n",
    "        input_variables=[\"context\", \"question\"])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=openai_project_index.as_retriever(),\n",
    "        # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
    "        chain_type=\"stuff\", )\n",
    "    \n",
    "    qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
    "    response = qa_chain.invoke(query)\n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3664a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"general-qa-tool\", return_direct=False)\n",
    "def general_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering general questions.\"\"\"\n",
    "    response = cypher_chain.invoke(query)\n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffe5c2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are the detailed information about the project named Skyhawks:\\n\\n- Name: Skyhawks\\n- Description: Skyhawks is a solution designed for founders who aim to excel in content marketing. The project utilizes proprietary AI technology to analyze the competition related to the chosen topic. It helps in creating optimized content quickly by leveraging state-of-the-art AI generation capabilities. This allows users to produce high-quality content efficiently and stay ahead in the competitive content marketing landscape.\\n- Complexity: High\\n\\nIf you need further information or have any specific questions about Skyhawks, feel free to ask!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_qa_tool.invoke(\"Provide me the detailed information of Skyhawks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16493e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/90/h9hy_l096_jcf3041fnkklp00000gn/T/ipykernel_2249/2653480292.py\", line 1, in <module>\n",
      "    general_qa_tool.invoke(\"Provide me the detailed information of Skyhawks.\")\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/langchain_core/tools/base.py\", line 599, in invoke\n",
      "    return self.run(tool_input, **kwargs)\n",
      "           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/langchain_core/tools/base.py\", line 883, in run\n",
      "    raise error_to_raise\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/langchain_core/tools/base.py\", line 852, in run\n",
      "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/langchain_core/tools/structured.py\", line 93, in _run\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/90/h9hy_l096_jcf3041fnkklp00000gn/T/ipykernel_2249/2493518892.py\", line 4, in general_qa_tool\n",
      "    response = cypher_chain.invoke(query)\n",
      "               ^^^^^^^^^^^^\n",
      "NameError: name 'cypher_chain' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "        etype, value, tb, tb_offset=tb_offset\n",
      "    )\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, number_of_lines_of_context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                                                           tb_offset)\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/IPython/core/ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/stack_data/utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/stack_data/core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/stack_data/core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/executing/executing.py\", line 283, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "    ~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tejasjay/Desktop/graphrag/.venv/lib/python3.13/site-packages/executing/executing.py\", line 80, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "general_qa_tool.invoke(\"Provide me the detailed information of Skyhawks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a781dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
