{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.0\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai==1.7.2\n",
      "  Downloading openai-1.7.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langchain-openai==0.0.2\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langchain-community==0.0.12\n",
      "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting langchainhub==0.1.14\n",
      "  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (1.4.54)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (3.11.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.0)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (1.33)\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain==0.1.0) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.0)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai==1.7.2) (4.13.2)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai==0.0.2)\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchainhub==0.1.14) (2.32.0.20250328)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.7.2) (3.10)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.7.2) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.0) (2.1)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain==0.1.0)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.0) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai==0.0.2) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (1.0.0)\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
      "Downloading langchain_openai-0.0.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.12-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.5.2-cp311-cp311-macosx_11_0_arm64.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, tenacity, packaging, tiktoken, marshmallow, langchainhub, openai, langsmith, dataclasses-json, langchain-core, langchain-openai, langchain-community, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.67.0\n",
      "    Uninstalling openai-1.67.0:\n",
      "      Successfully uninstalled openai-1.67.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.1.0 langchain-community-0.0.12 langchain-core-0.1.23 langchain-openai-0.0.2 langchainhub-0.1.14 langsmith-0.0.87 marshmallow-3.26.1 openai-1.7.2 packaging-23.2 tenacity-8.5.0 tiktoken-0.5.2 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain==0.1.0 openai==1.7.2 langchain-openai==0.0.2 langchain-community==0.0.12 langchainhub==0.1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load In Envrironment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                 model=\"gpt-4o-mini\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Message Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.\"),\n",
    "    HumanMessage(\"Tell me a joke.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Prince\n"
     ]
    }
   ],
   "source": [
    "username = \"Prince\"\n",
    "txt = f\"Hello {username}\"\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me historical fact about the {event} in {location}.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me historical fact about the World War II in Europe.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(event=\"World War II\", location=\"Europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_str = \"\"\"You are a helpful AI assistant. Given the \n",
    "following context, answer the question. If the answer can not be \n",
    "found in the context, simply say you DO NOT KNOW.\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_promt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=system_message_str,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_str = \"Can you provide details on:  {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=human_message_str,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [system_message_promt, human_message_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_prompt_template = ChatPromptTemplate(\n",
    "    messages=messages,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "context = \"France is a country in Europe. It's capital is Paris.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI assistant. Given the \\nfollowing context, answer the question. If the answer can not be \\nfound in the context, simply say you DO NOT KNOW.\\nContext: France is a country in Europe. It's capital is Paris.\\n\\nHuman: Can you provide details on:  What is the capital of France?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_prompt_template.format(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\n",
    "    chatbot_prompt_template.format(context=context, question=\"What is the capital of Kenya?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='DO NOT KNOW.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DO NOT KNOW.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatbot_prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": question\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I DO NOT KNOW.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"What is the capital of Kenya?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_openai_tools_agent\n",
    ")\n",
    "from langchain.tools import tool\n",
    "from langchain_core.tools import ToolException\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_type = Literal[\"add\", \"multiply\", \"substraction\", \"division\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"Calculator-tool\", return_direct=False)\n",
    "def calculator(operator: operator_type, a: float, b: float) -> float:\n",
    "    \"\"\"A simple calculator tool that can add, multiply, substract, or divide two numbers.\"\"\"\n",
    "    if operator == \"add\":\n",
    "        return a + b\n",
    "    elif operator == \"multiply\":\n",
    "        return a * b\n",
    "    elif operator == \"substraction\":\n",
    "        return a - b\n",
    "    elif operator == \"division\":\n",
    "        return a / b\n",
    "    else:\n",
    "        raise ToolException(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator-tool\n",
      "Calculator-tool(operator: Literal['add', 'multiply', 'substraction', 'division'], a: float, b: float) -> float - A simple calculator tool that can add, multiply, substract, or divide two numbers.\n",
      "False\n",
      "{'operator': {'title': 'Operator', 'enum': ['add', 'multiply', 'substraction', 'division'], 'type': 'string'}, 'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "print(calculator.name)\n",
    "print(calculator.description)\n",
    "print(calculator.return_direct)\n",
    "print(calculator.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.run({\"operator\": \"add\", \"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building A Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator-tool` with `{'operator': 'multiply', 'a': 2, 'b': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m6.0\u001b[0m\u001b[32;1m\u001b[1;3mThe product of 2 and 3 is 6.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What is the product of 2 and 3?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language To Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Employee`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    }
   ],
   "source": [
    "neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "    url=os.getenv(\"NEO4J_URL\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name=\"employee\",\n",
    "    node_label=\"Employee\",\n",
    "    text_node_properties=[\n",
    "        \"address\",\n",
    "        \"city\",\n",
    "        \"title\",\n",
    "        \"email\",\n",
    "        \"postalCode\"\n",
    "        \"note\",\n",
    "        \"firstName\",\n",
    "        \"lastName\",\n",
    "        \"region\"\n",
    "    ],\n",
    "    embedding_node_property=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\"Andrew\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Nancy\\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.'}),\n",
       " Document(page_content='\\naddress: 14 Garrett Hill\\ncity: London\\ntitle: Sales Manager\\nemail: \\npostalCodenote: \\nfirstName: Steven\\nlastName: Buchanan\\nregion: Unknown', metadata={'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.'})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.'}\n"
     ]
    }
   ],
   "source": [
    "print(result[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\n",
    "    \"Employee detail\", filter={\"country\": \"USA\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Nancy\\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.'}),\n",
       " Document(page_content='\\naddress: 722 Moss Bay Blvd.\\ncity: Kirkland\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Janet\\nlastName: Leverling\\nregion: WA', metadata={'employeeID': 3, 'hireDate': '1992-04-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000080540000424D80540000000000007600000028000000C0000000E0000000010004000000000000540000CE0E0000D80E0000000000', 'homePhone': '(206) 555-3412', 'photoPath': 'http://accweb/emmployees/leverling.bmp', 'country': 'USA', 'extension': 3355, 'postalCode': '98033', 'titleOfCourtesy': 'Ms.', 'birthDate': '1963-08-30 00:00:00.000', 'notes': 'Janet has a BS degree in chemistry from Boston College (1984). She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.'}),\n",
       " Document(page_content='\\naddress: 7 Houndstooth Rd.\\ncity: London\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Anne\\nlastName: Dodsworth\\nregion: Unknown', metadata={'employeeID': 9, 'hireDate': '1994-11-15 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D16540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4444', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'UK', 'extension': 452, 'postalCode': 'WG2 7LT', 'titleOfCourtesy': 'Ms.', 'birthDate': '1966-01-27 00:00:00.000', 'notes': 'Anne has a BA degree in English from St. Lawrence College.  She is fluent in French and German.'}),\n",
       " Document(page_content='\\naddress: 14 Garrett Hill\\ncity: London\\ntitle: Sales Manager\\nemail: \\npostalCodenote: \\nfirstName: Steven\\nlastName: Buchanan\\nregion: Unknown', metadata={'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.'})]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          First name: Nancy\n",
      "          Last name: Davolio\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: Janet\n",
      "          Last name: Leverling\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: Anne\n",
      "          Last name: Dodsworth\n",
      "          Title: Sales Representative\n",
      "          country: UK\n",
      "          \n",
      "\n",
      "          First name: Steven\n",
      "          Last name: Buchanan\n",
      "          Title: Sales Manager\n",
      "          country: UK\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for employee in result:\n",
    "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          First name: {clearned_page_content.get('firstName')}\n",
    "          Last name: {clearned_page_content.get('lastName')}\n",
    "          Title: {clearned_page_content.get('title')}\n",
    "          country: {employee.metadata.get('country')}\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\n",
    "    \"Employee detail\", filter={\"country\": {\"$ne\": 'UK'}}, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Nancy\\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.'}),\n",
       " Document(page_content='\\naddress: 722 Moss Bay Blvd.\\ncity: Kirkland\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfirstName: Janet\\nlastName: Leverling\\nregion: WA', metadata={'employeeID': 3, 'hireDate': '1992-04-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000080540000424D80540000000000007600000028000000C0000000E0000000010004000000000000540000CE0E0000D80E0000000000', 'homePhone': '(206) 555-3412', 'photoPath': 'http://accweb/emmployees/leverling.bmp', 'country': 'USA', 'extension': 3355, 'postalCode': '98033', 'titleOfCourtesy': 'Ms.', 'birthDate': '1963-08-30 00:00:00.000', 'notes': 'Janet has a BS degree in chemistry from Boston College (1984). She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.'})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ne\n",
    "$lt\n",
    "$lte\n",
    "$gte\n",
    "$gt\n",
    "$in\n",
    "$like\n",
    "$ilke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          First name: Nancy\n",
      "          Last name: Davolio\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: Janet\n",
      "          Last name: Leverling\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for employee in result:\n",
    "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          First name: {clearned_page_content.get('firstName')}\n",
    "          Last name: {clearned_page_content.get('lastName')}\n",
    "          Title: {clearned_page_content.get('title')}\n",
    "          country: {employee.metadata.get('country')}\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_template_str = \"\"\"\n",
    "Your job is to use the provided employee data to answer \n",
    "questions about their roles, performance, and experiences \n",
    "within the company. Use the following context to answer questions. \n",
    "Be as detailed as possible, but don't make up any information that's \n",
    "not from the context. If you don't know an answer, say you don't know.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=employee_details_chat_template_str\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"Can you provide details on: {question}?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [employee_details_chat_system_prompt, human_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate(\n",
    "    messages=messages,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=neo4j_graph_vector_index.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke(\"Give me profile details of Dodsworth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne Dodsworth is a Sales Representative at the company, located at 7 Houndstooth Rd. in London. She is part of the sales team and is responsible for handling sales activities for the company. Anne's email address and postal code are not provided in the context. Her region is listed as \"Unknown.\" If you need more specific information about Anne Dodsworth, please let me know.\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URL\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_template = \"\"\"\n",
    "Task:\n",
    "Generate Cypher query for a Neo4j graph database.\n",
    "\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note:\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything other than\n",
    "for you to construct a Cypher statement. Do not include any text except\n",
    "the generated Cypher statement. Make sure the direction of the relationship is\n",
    "correct in your queries. Make sure you alias both entities and relationships\n",
    "properly. Do not run any queries that would add to or delete from\n",
    "the database. Make sure to alias all statements that follow as with\n",
    "statement (e.g. WITH c as customer, o.orderID as order_id).\n",
    "If you need to divide numbers, make sure to\n",
    "filter the denominator to be non-zero.\n",
    "\n",
    "Examples:\n",
    "# Retrieve the total number of orders placed by each customer.\n",
    "MATCH (c:Customer)-[o:ORDERED_BY]->(order:Order)\n",
    "RETURN c.customerID AS customer_id, COUNT(o) AS total_orders\n",
    "# List the top 5 products with the highest unit price.\n",
    "MATCH (p:Product)\n",
    "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
    "ORDER BY unit_price DESC\n",
    "LIMIT 5\n",
    "# Find all employees who have processed orders.\n",
    "MATCH (e:Employee)-[r:PROCESSED_BY]->(o:Order)\n",
    "RETURN e.employeeID AS employee_id, COUNT(o) AS orders_processed\n",
    "String category values:\n",
    "Use existing strings and values from the schema provided. \n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    "    template=cypher_generation_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_template_str = \"\"\"\n",
    "You are an assistant that takes the results from a Neo4j Cypher query and forms a human-readable response. The query results section contains the results of a Cypher query that was generated based on a user's natural language question. The provided information is authoritative; you must never question it or use your internal knowledge to alter it. Make the answer sound like a response to the question.\n",
    "\n",
    "Query Results:\n",
    "{context}\n",
    "Question:\n",
    "{question}\n",
    "If the provided information is empty, respond by stating that you don't know the answer. Empty information is indicated by: []\n",
    "If the information is not empty, you must provide an answer using the results. If the question involves a time duration, assume the query results are in units of days unless specified otherwise.\n",
    "When names are provided in the query results, such as hospital names, be cautious of any names containing commas or other punctuation. For example, 'Jones, Brown and Murray' is a single hospital name, not multiple hospitals. Ensure that any list of names is presented clearly to avoid ambiguity and make the full names easily identifiable.\n",
    "Never state that you lack sufficient information if data is present in the query results. Always utilize the data provided.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], template=qa_generation_template_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    top_k=10,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    validate_cypher=True,\n",
    "    qa_prompt=qa_generation_prompt,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    qa_llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    cypher_llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the most expensive product?\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive product is Côte de Blaye, priced at $263.50.\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 5\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}, {'product_name': 'Thüringer Rostbratwurst', 'unit_price': 123.79}, {'product_name': 'Mishi Kobe Niku', 'unit_price': 97.0}, {'product_name': \"Sir Rodney's Marmalade\", 'unit_price': 81.0}, {'product_name': 'Carnarvon Tigers', 'unit_price': 62.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"List the top 5 products with the highest unit price.\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 products with the highest unit prices are:\n",
      "1. Côte de Blaye - $263.5\n",
      "2. Thüringer Rostbratwurst - $123.79\n",
      "3. Mishi Kobe Niku - $97.0\n",
      "4. Sir Rodney's Marmalade - $81.0\n",
      "5. Carnarvon Tigers - $62.5\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (s:Shipper)<-[sh:SHIPPED_BY]-(o:Order)\n",
      "RETURN s.shipperID AS shipper_id, s.companyName AS company_name, s.phone AS phone, COUNT(o) AS total_orders_shipped\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'shipper_id': 3, 'company_name': 'Federal Shipping', 'phone': '(503) 555-9931', 'total_orders_shipped': 87}, {'shipper_id': 1, 'company_name': 'Speedy Express', 'phone': '(503) 555-9831', 'total_orders_shipped': 67}, {'shipper_id': 2, 'company_name': 'United Package', 'phone': '(503) 555-3199', 'total_orders_shipped': 96}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me more details on each shipper as well as how many orders they have shipped.\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the details on each shipper along with the total number of orders they have shipped:\n",
      "\n",
      "1. Shipper ID: 3\n",
      "   Company Name: Federal Shipping\n",
      "   Phone: (503) 555-9931\n",
      "   Total Orders Shipped: 87\n",
      "\n",
      "2. Shipper ID: 1\n",
      "   Company Name: Speedy Express\n",
      "   Phone: (503) 555-9831\n",
      "   Total Orders Shipped: 67\n",
      "\n",
      "3. Shipper ID: 2\n",
      "   Company Name: United Package\n",
      "   Phone: (503) 555-3199\n",
      "   Total Orders Shipped: 96\n",
      "\n",
      "These are the details you requested!\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents In GraphRAG Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_template_str = \"\"\"\n",
    "Your job is to use the provided employee data to answer \n",
    "questions about their roles, performance, and experiences \n",
    "within the company. Use the following context to answer questions. \n",
    "Be as detailed as possible, but don't make up any information that's \n",
    "not from the context. If you don't know an answer, say you don't know.\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"employee-qa-tool\", return_direct=False)\n",
    "def employee_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering questions about employees who work at a company.\"\"\"\n",
    "    \n",
    "    employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"context\"],\n",
    "            template=employee_details_chat_template_str\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    human_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=\"Can you provide details on: {question}?\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    messages = [employee_details_chat_system_prompt, human_prompt]\n",
    "    \n",
    "    qa_prompt = ChatPromptTemplate(\n",
    "        messages=messages,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=neo4j_graph_vector_index.as_retriever(),\n",
    "        # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
    "        chain_type=\"stuff\",\n",
    "    )\n",
    "    \n",
    "    qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
    "    \n",
    "    response = qa_chain.invoke(query)\n",
    "    \n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The address of the Vice President, Andrew Fuller, is 908 W. Capital Way, Tacoma, WA.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_qa_tool.invoke(\"What is the address of the Vice president Andrew?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"general-qa-tool\", return_direct=False)\n",
    "def general_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering general questions about orders, order details, shipper, customers, and products.\"\"\"\n",
    "    response = cypher_chain.invoke(query)\n",
    "    \n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The most expensive product is \"Côte de Blaye\" with a unit price of 263.5.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_qa_tool.invoke(\"What is the most expensive product?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_openai_tools_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [employee_qa_tool, general_qa_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `general-qa-tool` with `{'query': 'most expensive product'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe most expensive product is \"Côte de Blaye\" with a unit price of 263.5.\u001b[0m\u001b[32;1m\u001b[1;3mThe most expensive product is \"Côte de Blaye\" with a unit price of $263.5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the most expensive product?',\n",
       " 'output': 'The most expensive product is \"Côte de Blaye\" with a unit price of $263.5.'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is the most expensive product?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `general-qa-tool` with `{'query': 'number of products ordered by customers'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (c:Customer)<-[o:ORDERED_BY]-(order:Order)-[i:INCLUDES]->(p:Product)\n",
      "RETURN c.customerID AS customer_id, COUNT(p) AS total_products_ordered\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'customer_id': 'VINET', 'total_products_ordered': 6}, {'customer_id': 'TOMSP', 'total_products_ordered': 2}, {'customer_id': 'HANAR', 'total_products_ordered': 6}, {'customer_id': 'VICTE', 'total_products_ordered': 5}, {'customer_id': 'SUPRD', 'total_products_ordered': 6}, {'customer_id': 'CHOPS', 'total_products_ordered': 3}, {'customer_id': 'RICSU', 'total_products_ordered': 4}, {'customer_id': 'WELLI', 'total_products_ordered': 2}, {'customer_id': 'HILAA', 'total_products_ordered': 3}, {'customer_id': 'ERNSH', 'total_products_ordered': 7}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe number of products ordered by customers are as follows:\n",
      "- VINET: 6 products\n",
      "- TOMSP: 2 products\n",
      "- HANAR: 6 products\n",
      "- VICTE: 5 products\n",
      "- SUPRD: 6 products\n",
      "- CHOPS: 3 products\n",
      "- RICSU: 4 products\n",
      "- WELLI: 2 products\n",
      "- HILAA: 3 products\n",
      "- ERNSH: 7 products\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `general-qa-tool` with `{'query': 'earliest shipper of the orders'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (s:Shipper)<-[r:SHIPPED_BY]-(o:Order)\n",
      "RETURN s.companyName AS shipper_name, MIN(o.shippedDate) AS earliest_shipped_date\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'shipper_name': 'Federal Shipping', 'earliest_shipped_date': '1996-07-15 00:00:00.000'}, {'shipper_name': 'Speedy Express', 'earliest_shipped_date': '1996-07-10 00:00:00.000'}, {'shipper_name': 'United Package', 'earliest_shipped_date': '1996-07-11 00:00:00.000'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe earliest shipper of the orders is Speedy Express, with an earliest shipped date of July 10, 1996.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `employee-qa-tool` with `{'query': 'Employees who processed the orders'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSure! Based on the provided employee data, the employees who processed the orders are:\n",
      "\n",
      "1. Nancy Davolio - Sales Representative in Seattle\n",
      "2. Robert King - Sales Representative in London\n",
      "\n",
      "These employees likely handle customer orders, process them in the company's system, and ensure timely delivery to customers.\u001b[0m\u001b[32;1m\u001b[1;3mThe products were ordered by customers in the quantities mentioned earlier. The shipper that shipped them the earliest is Speedy Express, with an earliest shipped date of July 10, 1996. The employees who processed these orders are Nancy Davolio and Robert King.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many products were ordered by customers, of which the shipper shipped them the earliest and which Employees processed them?',\n",
       " 'output': 'The products were ordered by customers in the quantities mentioned earlier. The shipper that shipped them the earliest is Speedy Express, with an earliest shipped date of July 10, 1996. The employees who processed these orders are Nancy Davolio and Robert King.'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"How many products were ordered by customers, of which the shipper shipped them the earliest and which Employees processed them?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
